---
title: "Regressão Linear BoxCox"
author: "Rogério Coelho"
date: "2025-02-11"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 10,
  fig.height = 6,
  out.width = '50%',
  warning = FALSE,
  message = FALSE
)
```

## Exercício **Auto MPG - uso de BOXCOX**

### Leitura do arquivo: auto-mpg.data

- Atribuição dos nomes das colunas e ajustes nos tipos de variáveis (categóricas e numéricas)
- A variável horsepower possui informações ausentes "?"


```{r, echo=TRUE, warning=FALSE, message=FALSE}
df_auto <- read.table("auto-mpg.data", quote="\"", comment.char="")
# Renomeando as colunas
colnames(df_auto) <- c("mpg", "cylinders", "displacement", "horsepower", 
                       "weight", "acceleration", "model_year", "origin", "car_name")
# Definindo as colunas numéricas e categóricas
colunas_num <- c("mpg", "displacement", "horsepower", "weight", "acceleration")
colunas_categoricas <- c("cylinders", "model_year", "origin", "car_name")
# Convertendo colunas categóricas
df_auto[colunas_categoricas] <- lapply(df_auto[colunas_categoricas], as.factor)
# Convertendo colunas numéricas
df_auto[colunas_num] <- lapply(df_auto[colunas_num], as.numeric) 
# separa marca do modelo
library(tidyverse)
df_auto <- df_auto %>%
  separate(car_name, into = c("marca", "modelo"), sep = " ", extra = "merge") %>%
  mutate(marca = as.factor(marca), modelo = as.factor(modelo))
summary(df_auto)
colunas_categoricas <- c("cylinders", "model_year", "origin", "marca", "modelo")
```

## Análise Univariada

### Histogramas e boxplots

```{r histogramas, echo=TRUE, message=FALSE, warning=FALSE, paged.print=TRUE}

# Usando lapply para gerar os histogramas
#lapply(colunas_num, function(col) {
#  hist(df_auto[[col]], main = paste("Histograma de", col), xlab = col, col = "lightblue", border = "black")
#})
# Usando lapply para gerar os histogramas com informações no topo das colunas
invisible(lapply(colunas_num, function(col) {
  # Gerando o histograma e armazenando o objeto
  h <- hist(df_auto[[col]], main = paste("Histograma de", col), 
            xlab = col, col = "lightblue", border = "black", plot = FALSE)
  
  # Desenhando o histograma
  hist(df_auto[[col]], main = paste("Histograma de", col), 
       xlab = col, col = "lightblue", border = "black")
  
  # Adicionando as informações no topo das colunas
  text(h$mids, h$counts, labels = h$counts, pos = 3, cex = 0.8, col = "red")  # Mostra os counts
  text(h$mids, h$density, labels = round(h$density, 2), pos = 1, cex = 0.8, col = "blue")  # Mostra a densidade
}))

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r boxplots}
# Usando lapply para gerar os boxplots
#lapply(colunas_num, function(col) {
#  boxplot(df_auto[[col]], main = paste("Boxplot de", col), xlab = col, col = "lightblue", border = "black")
#})
# Usando lapply para gerar os boxplots com informações de quartis e outros dados
invisible(lapply(colunas_num, function(col) {
  # Calculando as estatísticas do boxplot
  box_stats <- boxplot(df_auto[[col]], plot = FALSE)
  
  # Gerando o boxplot
  boxplot(df_auto[[col]], main = paste("Boxplot de", col), 
          ylab = col, col = "lightblue", border = "black")
  
  # Adicionando as informações no gráfico
  # Exibindo o mínimo, Q1, mediana, Q3, e máximo
  text(1, box_stats$stats[1], labels = paste("Mínimo: ", round(box_stats$stats[1], 2)), pos = 3, cex = 0.8, col = "red")
  text(1, box_stats$stats[2], labels = paste("Q1: ", round(box_stats$stats[2], 2)), pos = 3, cex = 0.8, col = "blue")
  text(1, box_stats$stats[3], labels = paste("Mediana: ", round(box_stats$stats[3], 2)), pos = 3, cex = 0.8, col = "black")
  text(1, box_stats$stats[4], labels = paste("Q3: ", round(box_stats$stats[4], 2)), pos = 3, cex = 0.8, col = "blue")
  text(1, box_stats$stats[5], labels = paste("Máximo: ", round(box_stats$stats[5], 2)), pos = 3, cex = 0.8, col = "red")
}))
```

## Resumo estatístico das colunas numéricas

```{r summary variáveis numéricas}
# Usando um loop for para gerar os resumos das colunas numéricas com seus nomes
for (col in colunas_num) {
  cat("\nResumo da coluna:", col, "\n")  # Exibe o nome da coluna
  print(summary(df_auto[[col]]))  # Exibe o resumo estatístico da coluna
}
```

### Resumo

- mpg: distribuição simétrica
- displacement: simetria positiva
- horsepower: simetria positiva e presença de outliers
- weight: leve assimetria positiva
- acceleration: distribuição simétrica


## Variáveis Categoricas

```{r}
# Loop para calcular frequências e criar gráficos para cada variável categórica
colunas_categoricas <- c("model_year", "origin", "marca")
for (var in colunas_categoricas) {
  # Calcular as frequências
  frequencias <- as.data.frame(table(df_auto[[var]]))
  colnames(frequencias) <- c("categoria", "frequencia")

  # Criar o gráfico de colunas
  plot <- ggplot(frequencias, aes(x = categoria, y = frequencia)) +
    geom_col(fill = "steelblue") +
    geom_text(aes(label = frequencia), vjust = -0.5) +  # Adiciona rótulos acima das barras
    labs(
      title = paste("Gráfico de Colunas -", var),  # Nome da variável no título
      x = "Categoria",
      y = "Frequência"
    ) +
    theme_minimal()

  # Exibir o gráfico
  print(plot)
}
```

## Entendendo mpg x cilindradas

```{r dispersão, message=FALSE, warning=FALSE, paged.print=TRUE}
# Converter a coluna 'cylinders' para numérica
df_auto$cylinders <- as.numeric(as.character(df_auto$cylinders))

# Criar o gráfico de dispersão com jitter e boxplots
ggplot(df_auto, aes(x = as.factor(cylinders), y = mpg)) +  # Usar as.factor para boxplot
  geom_boxplot(width = 0.5, alpha = 0.5, outlier.shape = NA) +  # Boxplot sem outliers
  geom_jitter(aes(color = origin),width = 0.15, height = 0, alpha = 0.45) +  # Pontos de dispersão
  labs(
    title = "Gráfico de Dispersão e Boxplot de MPG vs Cilindradas",
    x = "Cilindradas",
    y = "Milhas por Galão (MPG)"
  ) +
  theme_minimal()
df_auto$cylinders <- as.factor(df_auto$cylinders)
```


## Análise do gráfico

- Veículos com 4 cilindros são a maioria na amostra
  - maior amplitude em comparação com os demais
- 3 e 5 cilindros não possuem um quantidade significativa na amostra
- 6 e 8 cilindros possuem um consumo maior de combustível, sendo que 8 são os 


## Dispersão de MPG vs weight

- É possível perceber a presença de heterocedasticidade

```{r}
library(ggplot2)
library(rlang)

colunas <- colunas_num[-1]

# Loop para criar gráficos de dispersão
for (col in colunas) {
  # Criar o gráfico
  plot <- ggplot(df_auto, aes(x = .data[[col]], y = mpg, color = origin)) +
    geom_point() +  # Adiciona os pontos ao gráfico
    labs(
      title = paste("Gráfico de Dispersão de MPG vs", col),
      x = col,
      y = "Milhas por Galão (MPG)"
    ) +
    theme_minimal()
  
  # Exibir o gráfico
  print(plot)  # Corrige o erro chamando explicitamente o objeto do gráfico
}


```

## Heterocedasticidade

 - Presença de heterocedasticidade em todos os gŕaficos de dispersão
 - Os gráficos apresentam uma leve curvatura na dispersão
 
## Verificando a multicolinearidade 

```{r}
library(PerformanceAnalytics)
analise_correl <- select(df_auto, horsepower, displacement, weight, acceleration)
chart.Correlation((analise_correl),histogram=TRUE)
```

### Resulado

- Existe uma correlação muito forte entre as variáveis horsepower, cylinders, displacement e weight
- Optei por realizar uma regressão usando step wise para saber qual variável seria a melhor escolha para o modelo.
- Em relação a explicabilidade seria mais simples explicar a relação entre mpg e peso. Quanto mais pesado mais combustível o veículo consome. Potência também seria uma alternativa para explicação. Já displacement e cilindros nem tanto.

Dada a multicolinearidade existente uma opção seria utilizar PCA para construção do modelo, no entando não seria nada fácil explicar o comportamento.

## Análise PCA

- A Análise de Componentes Principais (PCA) tem como principal objetivo reduzir a dimensionalidade de um conjunto de dados, preservando ao máximo a variabilidade presente nas variáveis originais. Isso é feito transformando as variáveis correlacionadas em um novo conjunto de variáveis não correlacionadas, chamadas de componentes principais (PCs). Caso o modelo de regressão não fique bom, podemos testar um outro modelo usando os componentes principais calculados.


```{r}
library(ggplot2)
library(FactoMineR)
library(factoextra)

# Selecionar as variáveis de interesse
df_pca <- df_auto[, c("horsepower", "mpg", "displacement", "weight", "acceleration")]

# Remover linhas com valores ausentes (se necessário)
df_pca <- na.omit(df_pca)

# Padronizar as variáveis (opcional, mas recomendado)
df_pca <- scale(df_pca)

# Aplicar a PCA
pca_result <- prcomp(df_pca, scale = TRUE)

# Resumo dos resultados
summary(pca_result)

# Gráfico de scree plot
fviz_eig(pca_result)

# Gráfico das variáveis
fviz_pca_var(pca_result, col.var = "contrib", gradient.cols = c("blue", "yellow", "red"), repel = TRUE)

# Gráfico dos indivíduos
fviz_pca_ind(pca_result, col.ind = "cos2", gradient.cols = c("blue", "yellow", "red"), repel = TRUE)
```

## Transformação da Y usando boxcox

```{r}
library(car)
df_auto_modelo <- df_auto %>%
  select(mpg, weight, acceleration, model_year)
# Remover linhas com valores ausentes (se necessário)
df_auto_modelo <- na.omit(df_auto_modelo)
df_auto_modelo$weight <- df_auto_modelo$weight / 1000

# Calcula o lambda ótimo usando powerTransform (modelo sem covariáveis: mpg ~ 1)
lambda <- powerTransform(mpg ~ 1, data = df_auto_modelo)
print(summary(lambda))  # Verifique o resultado e o valor de lambda

# Extrai o lambda ótimo
lambda_opt <- lambda$lambda
cat("Lambda ótimo:", lambda_opt, "\n")

# Aplica a transformação Box-Cox na variável mpg usando bcPower
df_auto_modelo$mpg_boxcox <- bcPower(df_auto_modelo$mpg, lambda_opt)
```

## Criação do modelo

- df_auto_modelo dataframe com as variáveis 
  - Devido a multicolinearidade existente entre as variáveis
  - Decidi por: weight, acceleration, model_year (Mais fácil explicar influência do peso no comportamento do modelo)
- df_auto_modelo_dummies: dataframe com as dummies

```{r}
## Define o dataframe e variáveis que farão parte do modelo
df_auto_modelo <- df_auto_modelo %>%
  select(mpg_boxcox, weight, acceleration, model_year)

# Criar variáveis dummy para as variáveis categóricas
#reordenando para remover a dummy de maior volume
df_auto_modelo$model_year <- factor(df_auto_modelo$model_year, levels = c("73", "70", "71", "72", "74", "75", "76", "77", "78", "79", "80", "81", "82"))

# Criar variáveis dummy removendo uma categoria de referência "73"
df_auto_modelo_dummies <- df_auto_modelo %>%
  model.matrix(~ . , data = .) %>%  
  as.data.frame()
# Remove a coluna intercept
df_auto_modelo_dummies <- df_auto_modelo_dummies %>% select(-`(Intercept)`)
```

### observação
Poderia usar as variáveis categóricas diretamente sem criar as dummies, pois a step (chamada para Step Wise faz isso automaticamente)
Para escolher a casela de referência:
  - df_auto_modelo$model_year <- relevel(df_auto_modelo$model_year, ref = "73")  # Define "73" como referência


## Modelo nulo

```{r}
#modelo nulo
lm_mpg_nulo <- lm(mpg_boxcox ~ 1, data=df_auto_modelo_dummies) # modelo nulo 
summary(lm_mpg_nulo) 
```

## Modelo completo

```{r}
lm_mpg_full <- lm(mpg_boxcox ~ weight + acceleration + model_year70 + model_year71 + model_year72 + 
                    model_year74 + model_year75 + model_year76 + model_year77 + model_year78 + 
                    model_year79 + model_year80 + model_year81 + model_year82, 
                    data = df_auto_modelo_dummies) # modelo com todas as variáveis
summary(lm_mpg_full)

```

## VIF para verificar a multicolinearidade

```{r}
# Calcular o VIF
vif_valores <- vif(lm_mpg_full)
print(vif_valores)
```

## Step Wise

```{r}
# Step partindo do modelo nulo até o modelo completo
forw <- step(lm_mpg_nulo, scope=list(lower=lm_mpg_nulo, upper=lm_mpg_full), direction = "forward")
summary(forw)  
```

## Modelo Step Wise Final

- lm(formula = mpg_boxcox ~ weight + model_year80 + model_year82 + 
    model_year81 + model_year79 + model_year78 + model_year77 + 
    model_year76 + model_year74 + model_year75 + model_year71 + 
    acceleration, data = df_auto_modelo_dummies)

    
## Verificações dos resíduos

- Média em torno de zero
- Normalidade 
- Variância

```{r}
# melhor AIC

lm_mpg_aic <- lm(mpg_boxcox ~ weight + model_year80 + model_year82 + 
                   model_year81 + model_year79 + model_year78 + model_year77 + 
                   model_year76 + model_year74 + model_year75 + model_year71 + 
                   acceleration, data = df_auto_modelo_dummies)
summary(lm_mpg_aic)
library(olsrr)
ols_vif_tol(lm_mpg_aic)

media_residuos <- mean(residuals(lm_mpg_aic))
print(media_residuos) # Deve ser próximo de 0

```
### média pŕoxima de zero ... ok


### Teste de normalidade 

```{r}

hist(residuals(lm_mpg_aic), main = "Histograma dos Resíduos", xlab = "Resíduos")

# Teste de normalidade (Shapiro-Wilk)
resultado <- shapiro.test(residuals(lm_mpg_aic))
print(resultado$p.value)
# Não passou no teste de normalidade p-valor > 0.05 

# Verificar usando o teste de normalidade do KolmogorovSmirnov

residuos <- residuals(lm_mpg_aic)
desvio_residuos <- sd(residuos)

# Realiza o teste de Kolmogorov-Smirnov para verificar a normalidade
ks_test <- ks.test(residuos, "pnorm", mean = media_residuos, sd = desvio_residuos)

# Exibe o resultado do teste
print(ks_test)
```

### Não passou no teste de normalidade ao nível de significância de 5%
### Shapiro-Wilk nem Kolmogorov-Smirnov

## Normalidade dos resíduos

```{r}
qqnorm(residuals(lm_mpg_aic), main = "QQ Plot dos Resíduos")
qqline(residuals(lm_mpg_aic), col = "red")
```

### É possivel notar que nas estremidades o modelo não responderá bem, porém para valores mais centrais o modelo tem um bom ajuste

```{r}
# gráfico dos resíduos padronizados
residuos_padronizados <- rstandard(lm_mpg_aic)
plot(residuos_padronizados, main = "Resíduos Padronizados", ylab = "Resíduos Padronizados")
abline(h = c(-3, 3), col = "red") # Limites para outliers

```

### Resíduos padronizados devem estar distribuídos aleatoriamente em torno de 0. Valores fora dos limites ±3 (linhas vermelhas) são considerados potenciais outliers.

```{r}
library(lmtest)
bptest(lm_mpg_aic)
```

### Resultado Breusch-Pagan test
- Como o valor-p é menor que 0.05, rejeitamos a hipótese nula (H0) ao nível de significância de 5%.
- Isso indica que há evidências estatísticas de heterocedasticidade nos resíduos e compromete a validade das inferências do modelo linear.
- Os erros padrão das estimativas podem ser incorretos, afetando os testes de significância e intervalos de confiança.

## Resíduos vs. Valores Ajustados

```{r}
# Extrair os resíduos e os valores ajustados
residuos <- residuals(lm_mpg_aic)
valores_ajustados <- fitted(lm_mpg_aic)

# Criar o gráfico
plot(valores_ajustados, residuos,
     xlab = "Valores Ajustados",
     ylab = "Resíduos",
     main = "Resíduos vs. Valores Ajustados",
     pch = 20, col = "blue")  # Personalização dos pontos

# Adicionar uma linha horizontal em y = 0
abline(h = 0, col = "red", lwd = 2)
```

### Resultado 
- Os resíduos não estão distribuídos aleatoriamente em torno de y=0
- Isso indica heterocedasticidade (variância não constante).
- Padrão sistemático pode indicar que o modelo não capturou adequadamente a relação entre as variáveis.

## Alternativa Modelo PCA 
- Construir um modelo com as variáveis do PCA
- Usar os componentes principais como preditores no modelo, em vez das variáveis originais, e verificar se o desempenho do modelo melhora.

```{r}

# Remover as linhas com valores ausentes (NA) do data frame df_auto
df_auto_limpo <- na.omit(df_auto)

# Selecionar as variáveis numéricas para a PCA
df_pca <- df_auto_limpo[, c("horsepower", "mpg", "displacement", "weight", "acceleration")]

# Padronizar as variáveis (opcional, mas recomendado para PCA)
df_pca <- scale(df_pca)

# Aplicar a PCA
pca_result <- prcomp(df_pca, scale = TRUE)

# Resumo dos resultados da PCA
summary(pca_result)

# Criar um data frame com os componentes principais
df_pca_model <- as.data.frame(pca_result$x[, 1:3])  # Seleciona os 3 primeiros PCs
colnames(df_pca_model) <- c("PC1", "PC2", "PC3")    # Renomeia os PCs para facilitar

# Adicionar a variável dependente (mpg) ao data frame sincronizado
df_pca_model$mpg <- df_auto_limpo$mpg

# Ajustar o modelo de regressão linear usando os PCs como preditores
modelo_pca <- lm(mpg ~ PC1 + PC2 + PC3, data = df_pca_model)

# Resumo do modelo
summary(modelo_pca)

# Diagnóstico do modelo
#par(mfrow = c(2, 2))  # Configura layout para múltiplos gráficos
plot(modelo_pca)

# Teste de normalidade dos resíduos
shapiro.test(residuals(modelo_pca))

# Teste de homocedasticidade (Breusch-Pagan)
library(lmtest)
bptest(modelo_pca)

```

## Qualidade e Acurácia dos modelos

```{r , echo=FALSE}
# Calcular os valores ajustados pelo modelo com AIC
valores_ajustados_aic <- fitted(lm_mpg_aic)

# Calcular o RMSE para o modelo com AIC
rmse_aic <- sqrt(mean((df_auto$mpg - valores_ajustados_aic)^2))
cat("RMSE do modelo com AIC:", rmse_aic, "\n")

# Calcular os valores ajustados pelo modelo com PCA
valores_ajustados_pca <- fitted(modelo_pca)

# Calcular o RMSE para o modelo com PCA
rmse_pca <- sqrt(mean((df_pca_model$mpg - valores_ajustados_pca)^2))
cat("RMSE do modelo com PCA:", rmse_pca, "\n")

r2_aic <- summary(lm_mpg_aic)$r.squared
r2_pca <- summary(modelo_pca)$r.squared
cat("R² do modelo com AIC:", r2_aic, "\n")
cat("R² do modelo com PCA:", r2_pca, "\n")

# Modelo com AIC
mae_aic <- mean(abs(df_auto$mpg - fitted(lm_mpg_aic)))

# Modelo com PCA
mae_pca <- mean(abs(df_pca_model$mpg - fitted(modelo_pca)))

cat("MAE do modelo com AIC:", mae_aic, "\n")
cat("MAE do modelo com PCA:", mae_pca, "\n")

# Modelo com AIC
mse_aic <- mean((df_auto$mpg - fitted(lm_mpg_aic))^2)

# Modelo com PCA
mse_pca <- mean((df_pca_model$mpg - fitted(modelo_pca))^2)

cat("MSE do modelo com AIC:", mse_aic, "\n")
cat("MSE do modelo com PCA:", mse_pca, "\n")

cat("RMSE do modelo com AIC:", rmse_aic, "\n")
cat("RMSE do modelo com PCA:", rmse_pca, "\n")

# Modelo com AIC
mape_aic <- mean(abs((df_auto$mpg - fitted(lm_mpg_aic)) / df_auto$mpg)) * 100

# Modelo com PCA
mape_pca <- mean(abs((df_pca_model$mpg - fitted(modelo_pca)) / df_pca_model$mpg)) * 100

cat("MAPE do modelo com AIC:", mape_aic, "%\n")
cat("MAPE do modelo com PCA:", mape_pca, "%\n")

# Para o modelo com AIC
plot(fitted(lm_mpg_aic), residuals(lm_mpg_aic),
     xlab = "Valores Ajustados", ylab = "Resíduos",
     main = "Resíduos vs Valores Ajustados (AIC)")
abline(h = 0, col = "red")

# Para o modelo com PCA
plot(fitted(modelo_pca), residuals(modelo_pca),
     xlab = "Valores Ajustados", ylab = "Resíduos",
     main = "Resíduos vs Valores Ajustados (PCA)")
abline(h = 0, col = "red")


```

### Conclusões

- O modelo baseado na PCA supera amplamente o modelo baseado no AIC em termos de qualidade do ajuste e acurácia preditiva, conforme evidenciado pelas métricas calculadas.
- Os componentes principais (PCs) são combinações lineares das variáveis originais, o que pode dificultar a interpretação direta do modelo.











